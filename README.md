# 📘 データサイエンス講義（第1〜14回）

本リポジトリは、大学講義で体系的に学んだデータサイエンス実習の成果をまとめたものです。  
単なるツール使用の習得ではなく、統計学的な理解・機械学習の仕組み・実務的な前処理・モデル評価を一通り経験しました。  
以下は **各講義で得たスキルと理解** を詳細化したまとめになります。

## 📂　資料一覧 & 目次

- [フォルダ（資料置き場）](https://drive.google.com/drive/folders/1x3IKOgTYSeQvcBI8aflBWsxFJJCx-UqM?usp=sharing)

- [第1回 Python基礎]
- [第2回 数値計算]
- [第3回 データ操作1]
- [第4回 データ操作2]
- [第5回 データ可視化]
- [第6回 機械学習とは]
- [第7回 分類問題1]
- [第9回 分類問題2]
- [第10回 データ前処理1]
- [第11回 データ前処理2（次元削減）]
- [第12回 モデル選択・評価]
- [第14回 アンサンブル学習]
- [個人的なコメント・メモ]
- [その後の個人的取り組み（Kaggle的テーマ）について]
---

## 第1回 イントロダクション & Python基礎
- **スキル**  
  - Python の基礎文法（関数定義、制御構文、データ型、モジュール活用）。  
  - 環境構築（Colab, venv）を通じて再現性の重要性を理解。  
- **理解**  
  - データサイエンスのワークフローを俯瞰。  
  - 「手段としてのプログラミング」を位置づけ、分析の最終目的を常に意識する姿勢を獲得。

---

## 第2回 数値計算（NumPy）
- **スキル**  
  - `ndarray` によるベクトル・行列計算、ブロードキャストによる高速化。  
  - 統計量の算出（平均・分散・相関係数）と乱数生成の再現性確保。  
- **理解**  
  - ベクトル化計算の意義（計算速度・コード可読性）。  
  - 数値演算を統計的処理・シミュレーションに繋げる基盤を形成。

---

## 第3回 可視化（Matplotlib）
- **スキル**  
  - 散布図・ヒストグラム・箱ひげ図・折れ線グラフの作成。  
  - 凡例・軸ラベル・スタイル設定による「見やすい図表」の設計。  
- **理解**  
  - 可視化は「単なるグラフ作成」ではなく、**仮説発見・外れ値検出・分布把握** の第一歩であることを実感。

---

## 第4回 表形式データ処理（pandas）
- **スキル**  
  - CSV/Excel 読み込み、列操作、フィルタリング、groupby・集計、欠損処理。  
  - DataFrame 操作を使いこなし、EDA（探索的データ分析）の基盤を構築。  
- **理解**  
  - データ操作は機械学習以前に最重要であり、**データをどう整形するかで結果が決まる**ことを理解。

---

## 第5回 回帰入門（線形回帰）
- **スキル**  
  - `LinearRegression` による単回帰・重回帰分析。  
  - `r^2` によるモデルの説明力評価。  
- **理解**  
  - 回帰係数の意味を統計的に捉え、説明変数の影響度を議論できるようになった。  
  - 「予測精度だけでなく解釈性が重要」という視点を獲得。

---

## 第6回 機械学習の入り口
- **スキル**  
  - 画像データのベクトル化、特徴抽出の基本。  
  - Bag-of-Words 的発想でテキスト・画像を数値化。  
- **理解**  
  - **「機械学習は数値化された特徴量に依存する」** という大原則を体感。  

---

## 第7回 分類問題1（MLPClassifier, two-moons）
- **スキル**  
  - 多層パーセプトロン（MLP）の実装とハイパーパラメータ調整。  
  - ノード数・層数による過学習/汎化性能の変化を観察。  
- **理解**  
  - ニューラルネットワークの表現力と「局所最適」の概念を実験的に学習。  

---

## 第8回 特徴量とモデル設計
- **スキル**  
  - 説明変数の選択と、削除時の精度低下比較。  
  - モデルの構築よりも「変数設計」が重要であることを実習。  
- **理解**  
  - 単なる精度向上ではなく、**「どの変数が本質的要因か」を見極める** 観点を得た。  

---

## 第9回 分類問題2（digits / Fashion-MNIST）
- **スキル**  
  - ホールドアウト法によるモデル性能評価。  
  - MLP と k近傍法の比較実験。  
- **理解**  
  - モデルごとに得意・不得意があることを、手書き数字・画像分類で具体的に確認。  

---

## 第10回 データ前処理（Ames Housing）
- **スキル**  
  - 欠測処理（drop / 平均補完）、外れ値除去（IQR法）、カテゴリ変数のエンコーディング（順序・OneHot）。  
  - ヒストグラム・箱ひげ図による分布確認。  
- **理解**  
  - データ前処理が「分析の成否を分ける」ことを痛感。  

---

## 第11回 次元削減
- **スキル**  
  - スケーリング（MinMax, StandardScaler）、相関に基づく特徴選択、再帰的特徴削除（RFE）、主成分分析（PCA）。  
  - 累積寄与率の読み取りと次元圧縮。  
- **理解**  
  - 説明変数が増えると精度は向上するが、過学習リスクが高まることを確認。  
  - PCA により「情報の本質的軸」を抽出できる感覚を獲得。  

---

## 第12回 モデル評価
- **スキル**  
  - ロジスティック回帰・k近傍法・決定木・SVM など複数モデルを実装し交差検証。  
  - 学習曲線・検証曲線による過学習/学習不足の診断。  
  - グリッドサーチによるハイパーパラメータ最適化。  
- **理解**  
  - **「モデル選択は科学的に」** という姿勢を確立。  
  - 精度だけでなく「再現性・安定性・解釈可能性」のバランスを学ぶ。  

---

## 第13回 応用リサーチ
- **スキル**  
  - 官公庁データを活用し、出生率に関する仮説を立て、変数を設計。  
  - 相関分析から施策提案へ繋げるリサーチ的手法。  
- **理解**  
  - **「データサイエンスは社会課題解決に直結する」** ことを実感。  

- **応用課題**  
  - 相関関係を基に、具体的施策提案（女性の高等教育進学率と出生率の関係など）。
  - **具体的な内閣府のデータ・知見から、説明変数を措定した**
      - [内閣府：第3章　人口・経済・地域社会をめぐる現状と課題](https://www5.cao.go.jp/keizai-shimon/kaigi/special/future/sentaku/s3_1_2.html)
      - 「内閣府の調査によると＜女性の社会進出・価値観の多様化＞へ注目すると、女性の社会進出が進むに伴い、子どもを産むという選択による所得に対する影響が、出生率低下につながっているという側面もあるという。
      - この調査を参考に、女性の社会進出の背景を受けて，大学数と合計特殊出生率には相関があるのではと考え、説明変数とし、分析課題に取り組んだ。

---

## 第14回 アンサンブル学習
- **スキル**  
  - 投票法（VotingClassifier）、ランダムフォレスト、バギング、ブースティング。  
  - ROC-AUC による汎化性能の比較。  
- **理解**  
  - **単一モデルではなく、複数モデルを組み合わせることで精度・安定性が向上する** ことを確認。  

---

## 💬 個人的なコメント・メモ
- 第7回：ノード数増加で一時的に精度向上→過学習、モデル設計の難しさを体感。  
- 第11回：説明変数の個数を変化させる中で、適当な数を設定することで効率的に精度改善する知見を得た。  
- 第12回：学習曲線・検証曲線から、サンプル数と正則化のバランスを議論できるようになった。  
- 第14回：Voting により単体モデル以上の精度を実現でき、実務的な効果を実感。  

---

## 🏁 その後の個人的取り組み（Kaggle的テーマ）
- **Titanic 生存予測**：特徴量エンジニアリング（称号抽出、家族サイズ、デッキ）、アンサンブルで精度向上。  
- **California Housing**：前処理・回帰・GridSearchCV で価格予測。  
- **Ames Housing**：カテゴリ変数処理＋アンサンブルで精度改善。  

---
